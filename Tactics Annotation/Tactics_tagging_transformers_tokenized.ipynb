{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3df7b88f-872f-46b3-bcd2-4a5538efb8e6",
   "metadata": {
    "id": "3df7b88f-872f-46b3-bcd2-4a5538efb8e6"
   },
   "source": [
    "IMPORTING LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48bf358f-7d8a-47a9-b8ae-7dd2ff6a6d85",
   "metadata": {
    "id": "48bf358f-7d8a-47a9-b8ae-7dd2ff6a6d85"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import chess\n",
    "import chess.pgn\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9e7f06-bf25-4482-95e0-1a8f44873107",
   "metadata": {
    "id": "4d9e7f06-bf25-4482-95e0-1a8f44873107"
   },
   "source": [
    "POSITIONAL ENCODING ON TOKENIZED INPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a527935a-e1ea-423c-9656-68fe64c0b434",
   "metadata": {
    "id": "a527935a-e1ea-423c-9656-68fe64c0b434"
   },
   "outputs": [],
   "source": [
    "def pos_enc_matrix(L, d, n = 10000):\n",
    "    \"\"\"Create positional encoding matrix\n",
    "\n",
    "    Args:\n",
    "        L: Input dimension (length)\n",
    "        d: Output dimension (depth), even only\n",
    "        n: Constant for the sinusoidal functions\n",
    "\n",
    "    Returns:\n",
    "        numpy matrix of floats of dimension L-by-d. At element (k,2i) the value\n",
    "        is sin(k/n^(2i/d)) while at element (k,2i+1) the value is cos(k/n^(2i/d))\n",
    "    \"\"\"\n",
    "    assert d % 2 == 0, \"Output dimension needs to be an even integer\"\n",
    "    d2 = d//2\n",
    "    P = np.zeros((L, d))\n",
    "    k = np.arange(L).reshape(-1, 1)     # L-column vector\n",
    "    i = np.arange(d2).reshape(1, -1)    # d-row vector\n",
    "    denom = np.power(n, -i/d2)          # n**(-2*i/d)\n",
    "    args = k * denom                    # (L,d) matrix\n",
    "    P[:, ::2] = np.sin(args)\n",
    "    P[:, 1::2] = np.cos(args)\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0edb1d7-eba8-4015-b0a7-0051019e2c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#position embedding class for decoder (to be used as a layer)\n",
    "#@tf.keras.utils.register_keras_serializable()\n",
    "class PositionalEmbedding(tf.keras.layers.Layer):\n",
    "    \"\"\"Positional embedding layer. Assume tokenized input, transform into\n",
    "    embedding and returns positional-encoded output.\"\"\"\n",
    "    def __init__(self, seq_len, vocab_size, embed_dim, **kwargs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            seq_len: Input sequence length\n",
    "            vocab_size: Input vocab size, for setting up embedding matrix\n",
    "            embed_dim: Embedding vector size, for setting up embedding matrix\n",
    "        \"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "        self.seq_len = seq_len\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_dim = embed_dim     # d_model in paper\n",
    "        # token embedding layer: Convert integer token to D-dim float vector\n",
    "        self.token_embeddings = tf.keras.layers.Embedding(\n",
    "            input_dim = vocab_size, output_dim = embed_dim, mask_zero = True\n",
    "        )\n",
    "        # positional embedding layer: a matrix of hard-coded sine values\n",
    "        matrix = pos_enc_matrix(seq_len, embed_dim)\n",
    "        self.position_embeddings = tf.constant(matrix, dtype = \"float32\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"Input tokens convert into embedding vectors then superimposed\n",
    "        with position vectors\"\"\"\n",
    "        embedded_tokens = self.token_embeddings(inputs)\n",
    "        return embedded_tokens + self.position_embeddings\n",
    "\n",
    "    # this layer is using an Embedding layer, which can take a mask\n",
    "    # passing_mask_tensors_directly_to_layers\n",
    "    def compute_mask(self, *args, **kwargs):\n",
    "        return self.token_embeddings.compute_mask(*args, **kwargs)\n",
    "\n",
    "    def get_config(self):\n",
    "        # to make save and load a model using custom layer possible\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"seq_len\": self.seq_len,\n",
    "            \"vocab_size\": self.vocab_size,\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f78e445-b47d-4c80-a28a-002c3a9d57ca",
   "metadata": {},
   "source": [
    "ATTENTION FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6frVtTnmRTSt",
   "metadata": {
    "id": "6frVtTnmRTSt"
   },
   "outputs": [],
   "source": [
    "def self_attention(input_shape, prefix=\"att\", mask=False, **kwargs):\n",
    "    \"\"\"Self-attention layers at transformer encoder and decoder. Assumes its\n",
    "    input is the output from positional encoding layer.\n",
    "\n",
    "    Args:\n",
    "        prefix (str): The prefix added to the layer names\n",
    "        masked (bool): whether to use causal mask. Should be False on encoder and\n",
    "                       True on decoder. When True, a mask will be applied such that\n",
    "                       each location only has access to the locations before it.\n",
    "    \"\"\"\n",
    "    # create layers\n",
    "    inputs = tf.keras.layers.Input(shape=input_shape, dtype='float32',\n",
    "                                   name=f\"{prefix}_in1\")\n",
    "    attention = tf.keras.layers.MultiHeadAttention(name=f\"{prefix}_attn1\", **kwargs)\n",
    "    norm = tf.keras.layers.LayerNormalization(name=f\"{prefix}_norm1\")\n",
    "    add = tf.keras.layers.Add(name=f\"{prefix}_add1\")\n",
    "    # functional API to connect input to output\n",
    "    attout = attention(query=inputs, value=inputs, key=inputs,\n",
    "                       use_causal_mask=mask)\n",
    "    outputs = norm(add([inputs, attout]))\n",
    "    # create model and return\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs, name=f\"{prefix}_att\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ItGNhmF6Shx4",
   "metadata": {
    "id": "ItGNhmF6Shx4"
   },
   "outputs": [],
   "source": [
    "def cross_attention(input_shape, context_shape, prefix=\"att\", **kwargs):\n",
    "    \"\"\"Cross-attention layers at transformer decoder. Assumes its\n",
    "    input is the output from positional encoding layer at decoder\n",
    "    and context is the final output from encoder.\n",
    "\n",
    "    Args:\n",
    "        prefix (str): The prefix added to the layer names\n",
    "    \"\"\"\n",
    "    # create layers\n",
    "    context = tf.keras.layers.Input(shape=context_shape, dtype='float32',\n",
    "                                    name=f\"{prefix}_ctx2\")\n",
    "    inputs = tf.keras.layers.Input(shape=input_shape, dtype='float32',\n",
    "                                   name=f\"{prefix}_in2\")\n",
    "    attention = tf.keras.layers.MultiHeadAttention(name=f\"{prefix}_attn2\", **kwargs)\n",
    "    norm = tf.keras.layers.LayerNormalization(name=f\"{prefix}_norm2\")\n",
    "    add = tf.keras.layers.Add(name=f\"{prefix}_add2\")\n",
    "    # functional API to connect input to output\n",
    "    attout = attention(query=inputs, value=context, key=context)\n",
    "    outputs = norm(add([attout, inputs]))\n",
    "    # create model and return\n",
    "    model = tf.keras.Model(inputs=[(context, inputs)], outputs=outputs,\n",
    "                           name=f\"{prefix}_cross\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "l17Awf5PSoZ1",
   "metadata": {
    "id": "l17Awf5PSoZ1"
   },
   "outputs": [],
   "source": [
    "def feed_forward(input_shape, model_dim, ff_dim, dropout=0.1, prefix=\"ff\"):\n",
    "    \"\"\"Feed-forward layers at transformer encoder and decoder. Assumes its\n",
    "    input is the output from an attention layer with add & norm, the output\n",
    "    is the output of one encoder or decoder block\n",
    "\n",
    "    Args:\n",
    "        model_dim (int): Output dimension of the feed-forward layer, which\n",
    "                         is also the output dimension of the encoder/decoder\n",
    "                         block\n",
    "        ff_dim (int): Internal dimension of the feed-forward layer\n",
    "        dropout (float): Dropout rate\n",
    "        prefix (str): The prefix added to the layer names\n",
    "    \"\"\"\n",
    "    # create layers\n",
    "    inputs = tf.keras.layers.Input(shape=input_shape, dtype='float32',\n",
    "                                   name=f\"{prefix}_in3\")\n",
    "    dense1 = tf.keras.layers.Dense(ff_dim, name=f\"{prefix}_ff1\", activation=\"relu\")\n",
    "    dense2 = tf.keras.layers.Dense(model_dim, name=f\"{prefix}_ff2\")\n",
    "    drop = tf.keras.layers.Dropout(dropout, name=f\"{prefix}_drop\")\n",
    "    add = tf.keras.layers.Add(name=f\"{prefix}_add3\")\n",
    "    # functional API to connect input to output\n",
    "    ffout = drop(dense2(dense1(inputs)))\n",
    "    norm = tf.keras.layers.LayerNormalization(name=f\"{prefix}_norm3\")\n",
    "    outputs = norm(add([inputs, ffout]))\n",
    "    # create model and return\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs, name=f\"{prefix}_ff\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ZlPembyTStg1",
   "metadata": {
    "id": "ZlPembyTStg1"
   },
   "outputs": [],
   "source": [
    "def encoder(input_shape, key_dim, ff_dim, dropout=0.1, prefix=\"enc\", **kwargs):\n",
    "    \"\"\"One encoder unit. The input and output are in the same shape so we can\n",
    "    daisy chain multiple encoder units into one larger encoder\"\"\"\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Input(shape=input_shape, dtype='float32', name=f\"{prefix}_in0\"),\n",
    "        self_attention(input_shape, prefix=prefix, key_dim=key_dim, mask=False, **kwargs),\n",
    "        feed_forward(input_shape, key_dim, ff_dim, dropout, prefix),\n",
    "    ], name=prefix)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "Djop6srISuth",
   "metadata": {
    "id": "Djop6srISuth"
   },
   "outputs": [],
   "source": [
    "def decoder(input_shape, key_dim, ff_dim, dropout=0.1, prefix=\"dec\", **kwargs):\n",
    "    \"\"\"One decoder unit. The input and output are in the same shape so we can\n",
    "    daisy chain multiple decoder units into one larger decoder. The context\n",
    "    vector is also assumed to be the same shape for convenience\"\"\"\n",
    "    inputs = tf.keras.layers.Input(shape=input_shape, dtype='float32',\n",
    "                                   name=f\"{prefix}_in0\")\n",
    "    context = tf.keras.layers.Input(shape=input_shape, dtype='float32',\n",
    "                                    name=f\"{prefix}_ctx0\")\n",
    "    attmodel = self_attention(input_shape, key_dim=key_dim, mask=True,\n",
    "                              prefix=prefix, **kwargs)\n",
    "    crossmodel = cross_attention(input_shape, input_shape, key_dim=key_dim,\n",
    "                                 prefix=prefix, **kwargs)\n",
    "    ffmodel = feed_forward(input_shape, key_dim, ff_dim, dropout, prefix)\n",
    "    x = attmodel(inputs)\n",
    "    x = crossmodel([(context, x)])\n",
    "    output = ffmodel(x)\n",
    "    model = tf.keras.Model(inputs=[(inputs, context)], outputs=output, name=prefix)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b43dcd-8f53-46e7-b60c-3d9d8658d113",
   "metadata": {
    "id": "e4b43dcd-8f53-46e7-b60c-3d9d8658d113"
   },
   "source": [
    "BUILDING THE TRANSFORMER MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "MEQWrHkaTBS1",
   "metadata": {
    "id": "MEQWrHkaTBS1"
   },
   "outputs": [],
   "source": [
    "def transformer(num_layers, num_heads, seq_len_enc, seq_len_dec, key_dim, ff_dim, vocab_size_src,\n",
    "                vocab_size_tgt, dropout=0.1, name=\"transformer\"):\n",
    "    embed_shape_enc = (seq_len_enc, key_dim)  # output shape of the positional embedding layer (encoder)\n",
    "    embed_shape_dec = (seq_len_dec, key_dim)\n",
    "    # set up layers\n",
    "    input_enc = tf.keras.layers.Input(shape=(seq_len_enc,), dtype=\"float32\",\n",
    "                                      name=\"encoder_inputs\")\n",
    "    input_dec = tf.keras.layers.Input(shape=(seq_len_dec,), dtype=\"int32\",\n",
    "                                      name=\"decoder_inputs\")\n",
    "    embed_enc = PositionalEmbedding(seq_len_enc, vocab_size_src, key_dim, name=\"embed_enc\")\n",
    "    embed_dec = PositionalEmbedding(seq_len_dec, vocab_size_tgt, key_dim, name=\"embed_dec\")\n",
    "    encoders = [encoder(input_shape=embed_shape_enc, key_dim=key_dim,\n",
    "                        ff_dim=ff_dim, dropout=dropout, prefix=f\"enc{i}\",\n",
    "                        num_heads=num_heads)\n",
    "                for i in range(num_layers)]\n",
    "    decoders = [decoder(input_shape=embed_shape_dec, key_dim=key_dim,\n",
    "                        ff_dim=ff_dim, dropout=dropout, prefix=f\"dec{i}\",\n",
    "                        num_heads=num_heads)\n",
    "                for i in range(num_layers)]\n",
    "    final = tf.keras.layers.Dense(vocab_size_tgt, name=\"linear\")\n",
    "    # build output\n",
    "    x1 = embed_enc(input_enc)\n",
    "    x2 = embed_dec(input_dec)\n",
    "    for layer in encoders:\n",
    "        x1 = layer(x1)\n",
    "    for layer in decoders:\n",
    "        x2 = layer([x2, x1])\n",
    "    output = final(x2)\n",
    "    # XXX keep this try-except block\n",
    "    try:\n",
    "        del output._keras_mask\n",
    "    except AttributeError:\n",
    "        pass\n",
    "    model = tf.keras.Model(inputs=[input_enc, input_dec], outputs=output, name=name)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0e10a7-bd7a-4f61-af30-62e2b7a6ee52",
   "metadata": {
    "id": "cd0e10a7-bd7a-4f61-af30-62e2b7a6ee52"
   },
   "source": [
    "CUSTOM LEARNING RATE SCHEDULING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe6a79d5-36be-494a-8720-f50054599be9",
   "metadata": {
    "id": "fe6a79d5-36be-494a-8720-f50054599be9"
   },
   "outputs": [],
   "source": [
    "#@tf.keras.utils.register_keras_serializable()\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    \"Custom learning rate for Adam optimizer\"\n",
    "    def __init__(self, key_dim, warmup_steps = 4000):\n",
    "        super().__init__()\n",
    "        self.key_dim = key_dim\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.d = tf.cast(self.key_dim, tf.float32)\n",
    "\n",
    "    def __call__(self, step):\n",
    "        step = tf.cast(step, dtype = tf.float32)\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "        return tf.math.rsqrt(self.d) * tf.math.minimum(arg1, arg2)\n",
    "\n",
    "    def get_config(self):\n",
    "        # to make save and load a model using custom layer possible0\n",
    "        config = {\n",
    "            \"key_dim\": self.key_dim,\n",
    "            \"warmup_steps\": self.warmup_steps,\n",
    "        }\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20702766-e674-4483-813b-fa3c37ae3325",
   "metadata": {
    "id": "20702766-e674-4483-813b-fa3c37ae3325"
   },
   "source": [
    "LOSS FUNCTION AND EVALUATION METRIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33dd8cf0-1be9-475b-a2f9-3eb2719c4a60",
   "metadata": {
    "id": "33dd8cf0-1be9-475b-a2f9-3eb2719c4a60"
   },
   "outputs": [],
   "source": [
    "def masked_loss(label, pred):\n",
    "    mask = label != 0\n",
    "    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True, reduction = 'none')\n",
    "    loss = loss_object(label, pred)\n",
    "    mask = tf.cast(mask, dtype=loss.dtype)\n",
    "    loss *= mask\n",
    "    loss = tf.reduce_sum(loss)/tf.reduce_sum(mask)\n",
    "    return loss\n",
    "\n",
    "def masked_accuracy(label, pred):\n",
    "    pred = tf.argmax(pred, axis = 2)\n",
    "    label = tf.cast(label, pred.dtype)\n",
    "    match = label == pred\n",
    "    mask = label != 0\n",
    "    match = match & mask\n",
    "    match = tf.cast(match, dtype = tf.float32)\n",
    "    mask = tf.cast(mask, dtype = tf.float32)\n",
    "    return tf.reduce_sum(match)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jK83rGgVRNlZ",
   "metadata": {
    "id": "jK83rGgVRNlZ"
   },
   "source": [
    "READING THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38643ca1-1914-4761-aca5-a384cc451ba7",
   "metadata": {
    "id": "38643ca1-1914-4761-aca5-a384cc451ba7"
   },
   "outputs": [],
   "source": [
    "with open('start_fens.txt', 'r') as s:\n",
    "    start_fens = [line.strip() for line in s.readlines()]\n",
    "with open('themes.txt', 'r') as t:\n",
    "    themes = [line.strip() for line in t.readlines()]\n",
    "with open('moves.pkl', 'rb') as m:\n",
    "    moves = pickle.load(m)\n",
    "with open('moves_san_nosym.pkl', 'rb') as ms:\n",
    "    moves_san = pickle.load(ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4bcf992-3f17-4875-b993-013cc043d768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# moves_san = []\n",
    "# for i in range(len(start_fens)):\n",
    "#     board = chess.Board(start_fens[i])\n",
    "#     moves_san_i = []\n",
    "#     for move in moves[i]:\n",
    "#         moves_san_i.append(board.san(move))\n",
    "#         board.push(move)\n",
    "#     moves_san.append(moves_san_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a385687b-6867-450f-b605-7c465eeba0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('moves_san.pkl', 'wb') as ms:\n",
    "#     pickle.dump(moves_san, ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1r9Idfg2RfpX",
   "metadata": {
    "id": "1r9Idfg2RfpX"
   },
   "outputs": [],
   "source": [
    "indices = [i for i in range(len(start_fens)) if len(themes[i].split(' ')) <= 8 and len(moves[i]) < 9] #filtering the data based on analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e588ab3-ba06-479b-8ec1-3a91c9e7881c",
   "metadata": {
    "id": "2e588ab3-ba06-479b-8ec1-3a91c9e7881c"
   },
   "source": [
    "TOKENIZING THE DECODER I/O (ONLY ON TRAINING DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8d96ee9-b58a-45b1-bd8f-d13105db9352",
   "metadata": {
    "id": "f8d96ee9-b58a-45b1-bd8f-d13105db9352"
   },
   "outputs": [],
   "source": [
    "#Note: vocab_size and seq_length are to be determined after careful examination of the dataset (done above)!\n",
    "vocab_size_enc = 5000\n",
    "vocab_size_dec = 37 #tbd from data (themes)\n",
    "seq_len_dec = 8 #tbd from data\n",
    "#seq_len_enc = 9 #tbd from data\n",
    "seq_len_enc = 8\n",
    "vectorizer_enc = tf.keras.layers.TextVectorization(\n",
    "    max_tokens = vocab_size_enc,\n",
    "    standardize = None,\n",
    "    split = \"whitespace\",\n",
    "    output_mode = \"int\",\n",
    "    output_sequence_length = seq_len_enc\n",
    ")\n",
    "vectorizer_dec = tf.keras.layers.TextVectorization(\n",
    "    max_tokens = vocab_size_dec,\n",
    "    standardize = None,\n",
    "    split = \"whitespace\",\n",
    "    output_mode = \"int\",\n",
    "    output_sequence_length = seq_len_dec + 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0e7deb-4e32-4ae1-8cdd-10d0816b3cc2",
   "metadata": {
    "id": "7b0e7deb-4e32-4ae1-8cdd-10d0816b3cc2"
   },
   "source": [
    "TRAIN-TEST SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b06a39ee-e5a5-46da-9200-42fcc80c83e2",
   "metadata": {
    "id": "b06a39ee-e5a5-46da-9200-42fcc80c83e2"
   },
   "outputs": [],
   "source": [
    "ind_train, ind_test_val = train_test_split(indices, test_size = 0.3, shuffle = True, random_state = 42)\n",
    "ind_val, ind_test = train_test_split(ind_test_val, test_size = 0.5, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7fa77af-2c1e-4db5-bd4f-100ad514122b",
   "metadata": {
    "id": "a7fa77af-2c1e-4db5-bd4f-100ad514122b"
   },
   "outputs": [],
   "source": [
    "themes_train = [themes[i] for i in ind_train]\n",
    "moves_san_train = [' '.join(moves_san[i]) for i in ind_train]\n",
    "themes_val = [themes[i] for i in ind_val]\n",
    "moves_san_val = [' '.join(moves_san[i]) for i in ind_val]\n",
    "vectorizer_dec.adapt(themes_train) #fitting the vectorizer on the training themes data\n",
    "vectorizer_enc.adapt(moves_san_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "08f86934-d7a4-4e30-8f8c-1f2b43a47ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vectorizer.pkl', 'wb') as fp:\n",
    "    data = {\n",
    "        \"enc_config\":  vectorizer_enc.get_config(),\n",
    "        \"enc_weights\": vectorizer_enc.get_weights(),\n",
    "        \"dec_config\":  vectorizer_dec.get_config(),\n",
    "        \"dec_weights\": vectorizer_dec.get_weights(),\n",
    "    }\n",
    "    pickle.dump(data, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "833c4493-6b9a-4d6b-be18-dac4f0e967c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_enc_loaded = tf.keras.layers.TextVectorization.from_config(data['enc_config'])\n",
    "vectorizer_enc_loaded.set_weights(data['enc_weights'])\n",
    "vectorizer_dec_loaded = tf.keras.layers.TextVectorization.from_config(data['dec_config'])\n",
    "vectorizer_dec_loaded.set_weights(data['dec_weights'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6480ccc2-5ead-4528-a306-e3a0a998e0f3",
   "metadata": {
    "id": "6480ccc2-5ead-4528-a306-e3a0a998e0f3"
   },
   "source": [
    "PREPARING THE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cbb17bd4-bbf3-4329-93c5-705cd0df8799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up Dataset object\n",
    "def format_dataset(moves_san, themes):\n",
    "    vect_enc = vectorizer_enc(moves_san)\n",
    "    vect_dec = vectorizer_dec(themes)\n",
    "    source = {\"encoder_inputs\": vect_enc,\n",
    "              \"decoder_inputs\": vect_dec[:, :-1]}\n",
    "    target = vect_dec[:, 1:]\n",
    "    return (source, target)\n",
    "\n",
    "def make_dataset(moves_san, themes, batch_size=64):\n",
    "    \"\"\"Create TensorFlow Dataset for the sentence pairs\"\"\"\n",
    "    # convert them into list, and then create tensors\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((moves_san, themes))\n",
    "    return dataset.shuffle(2048) \\\n",
    "                  .batch(batch_size).map(format_dataset) \\\n",
    "                  .prefetch(16).cache()\n",
    "\n",
    "train_ds = make_dataset(moves_san_train, themes_train)\n",
    "val_ds = make_dataset(moves_san_val, themes_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f388fed-3d20-4b7f-a151-8bff10cb1389",
   "metadata": {
    "id": "0f388fed-3d20-4b7f-a151-8bff10cb1389"
   },
   "source": [
    "TRAINING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1e4941a9-3c4f-46b5-82ee-1ad2db7831dd",
   "metadata": {
    "id": "1e4941a9-3c4f-46b5-82ee-1ad2db7831dd"
   },
   "outputs": [],
   "source": [
    "#comb tried = [4,8,192,512,0.1]\n",
    "num_layers = 4\n",
    "num_heads = 8\n",
    "key_dim = 128\n",
    "ff_dim = 512\n",
    "dropout = 0.1\n",
    "model = transformer(num_layers, num_heads, seq_len_enc, seq_len_dec, key_dim, ff_dim, vocab_size_enc, vocab_size_dec, dropout)\n",
    "lr = CustomSchedule(key_dim)\n",
    "optimizer = tf.keras.optimizers.Adam(lr, beta_1 = 0.9, beta_2 = 0.98, epsilon = 1e-9)\n",
    "model.compile(loss = masked_loss, optimizer = optimizer, metrics = [masked_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "77975f8c-d379-4729-a2df-a7ff0edb5157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13158/13158 [==============================] - 7666s 574ms/step - loss: 1.0897 - masked_accuracy: 0.6753 - val_loss: 0.8337 - val_masked_accuracy: 0.7354\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2030773eb90>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 1\n",
    "model.fit(train_ds, epochs = epochs, validation_data = val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "HX79ejvYSBnF",
   "metadata": {
    "id": "HX79ejvYSBnF"
   },
   "outputs": [],
   "source": [
    "model.save('trans_model_tokenized_1.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pF3SPvsXCjto",
   "metadata": {
    "id": "pF3SPvsXCjto"
   },
   "source": [
    "LOADING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "IdpRsChZhTru",
   "metadata": {
    "id": "IdpRsChZhTru"
   },
   "outputs": [],
   "source": [
    "custom_objects = {\"PositionalEmbedding\": PositionalEmbedding,\n",
    "                  \"CustomSchedule\": CustomSchedule,\n",
    "                  \"masked_loss\": masked_loss,\n",
    "                  \"masked_accuracy\": masked_accuracy}\n",
    "with tf.keras.utils.custom_object_scope(custom_objects):\n",
    "    model_loaded = tf.keras.models.load_model(\"trans_model_tokenized_1.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6jSZrrY7GztC",
   "metadata": {
    "id": "6jSZrrY7GztC"
   },
   "source": [
    "MODEL EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5368a603-5c5f-4d8d-95c7-aa5b970f44c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(moves_san, seq_len_dec, model, vectorizer_enc, vectorizer_dec):\n",
    "    \"\"\"Create the translated sentence\"\"\"\n",
    "    enc_tokens = vectorizer_enc([moves_san])\n",
    "    lookup = list(vectorizer_dec.get_vocabulary())\n",
    "    start_sentinel, end_sentinel = \"[start]\", \"[end]\"\n",
    "    output_sentence = [start_sentinel]\n",
    "    # generate the translated sentence word by word\n",
    "    for i in range(seq_len_dec):\n",
    "        vector = vectorizer_dec([\" \".join(output_sentence)])\n",
    "        #assert vector.shape == (1, seq_len_dec + 1)\n",
    "        dec_tokens = vector[:, :-1]\n",
    "        #assert dec_tokens.shape == (1, seq_len_dec)\n",
    "        pred = model([enc_tokens, dec_tokens])\n",
    "        #assert pred.shape == (1, seq_len_dec, vocab_size_dec)\n",
    "        word = lookup[np.argmax(pred[0, i, :])]\n",
    "        output_sentence.append(word)\n",
    "        if word == end_sentinel:\n",
    "            break\n",
    "    return output_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "08b8df38-82c6-476b-b481-bea455b70d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "moves_san_test = [' '.join(moves_san[i]) for i in ind_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3d16264a-a60e-4337-ab12-b7e81344ec95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" viewBox=\"0 0 390 390\" width=\"390\" height=\"390\"><desc><pre>. . . . . . k .\n",
       ". . . r . . . .\n",
       ". . . . . n . .\n",
       ". . Q . . . . .\n",
       ". . . . . . . .\n",
       "P . . . . . P .\n",
       ". P . . r . . .\n",
       ". . . . . . K .</pre></desc><defs><g id=\"white-pawn\" class=\"white pawn\"><path d=\"M22.5 9c-2.21 0-4 1.79-4 4 0 .89.29 1.71.78 2.38C17.33 16.5 16 18.59 16 21c0 2.03.94 3.84 2.41 5.03-3 1.06-7.41 5.55-7.41 13.47h23c0-7.92-4.41-12.41-7.41-13.47 1.47-1.19 2.41-3 2.41-5.03 0-2.41-1.33-4.5-3.28-5.62.49-.67.78-1.49.78-2.38 0-2.21-1.79-4-4-4z\" fill=\"#fff\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" /></g><g id=\"white-queen\" class=\"white queen\" fill=\"#fff\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M8 12a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM24.5 7.5a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM41 12a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM16 8.5a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM33 9a2 2 0 1 1-4 0 2 2 0 1 1 4 0z\" /><path d=\"M9 26c8.5-1.5 21-1.5 27 0l2-12-7 11V11l-5.5 13.5-3-15-3 15-5.5-14V25L7 14l2 12zM9 26c0 2 1.5 2 2.5 4 1 1.5 1 1 .5 3.5-1.5 1-1.5 2.5-1.5 2.5-1.5 1.5.5 2.5.5 2.5 6.5 1 16.5 1 23 0 0 0 1.5-1 0-2.5 0 0 .5-1.5-1-2.5-.5-2.5-.5-2 .5-3.5 1-2 2.5-2 2.5-4-8.5-1.5-18.5-1.5-27 0z\" stroke-linecap=\"butt\" /><path d=\"M11.5 30c3.5-1 18.5-1 22 0M12 33.5c6-1 15-1 21 0\" fill=\"none\" /></g><g id=\"white-king\" class=\"white king\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M22.5 11.63V6M20 8h5\" stroke-linejoin=\"miter\" /><path d=\"M22.5 25s4.5-7.5 3-10.5c0 0-1-2.5-3-2.5s-3 2.5-3 2.5c-1.5 3 3 10.5 3 10.5\" fill=\"#fff\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M11.5 37c5.5 3.5 15.5 3.5 21 0v-7s9-4.5 6-10.5c-4-6.5-13.5-3.5-16 4V27v-3.5c-3.5-7.5-13-10.5-16-4-3 6 5 10 5 10V37z\" fill=\"#fff\" /><path d=\"M11.5 30c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0\" /></g><g id=\"black-knight\" class=\"black knight\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M 22,10 C 32.5,11 38.5,18 38,39 L 15,39 C 15,30 25,32.5 23,18\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 24,18 C 24.38,20.91 18.45,25.37 16,27 C 13,29 13.18,31.34 11,31 C 9.958,30.06 12.41,27.96 11,28 C 10,28 11.19,29.23 10,30 C 9,30 5.997,31 6,26 C 6,24 12,14 12,14 C 12,14 13.89,12.1 14,10.5 C 13.27,9.506 13.5,8.5 13.5,7.5 C 14.5,6.5 16.5,10 16.5,10 L 18.5,10 C 18.5,10 19.28,8.008 21,7 C 22,7 22,10 22,10\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 9.5 25.5 A 0.5 0.5 0 1 1 8.5,25.5 A 0.5 0.5 0 1 1 9.5 25.5 z\" style=\"fill:#ececec; stroke:#ececec;\" /><path d=\"M 15 15.5 A 0.5 1.5 0 1 1 14,15.5 A 0.5 1.5 0 1 1 15 15.5 z\" transform=\"matrix(0.866,0.5,-0.5,0.866,9.693,-5.173)\" style=\"fill:#ececec; stroke:#ececec;\" /><path d=\"M 24.55,10.4 L 24.1,11.85 L 24.6,12 C 27.75,13 30.25,14.49 32.5,18.75 C 34.75,23.01 35.75,29.06 35.25,39 L 35.2,39.5 L 37.45,39.5 L 37.5,39 C 38,28.94 36.62,22.15 34.25,17.66 C 31.88,13.17 28.46,11.02 25.06,10.5 L 24.55,10.4 z \" style=\"fill:#ececec; stroke:none;\" /></g><g id=\"black-rook\" class=\"black rook\" fill=\"#000\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 39h27v-3H9v3zM12.5 32l1.5-2.5h17l1.5 2.5h-20zM12 36v-4h21v4H12z\" stroke-linecap=\"butt\" /><path d=\"M14 29.5v-13h17v13H14z\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M14 16.5L11 14h23l-3 2.5H14zM11 14V9h4v2h5V9h5v2h5V9h4v5H11z\" stroke-linecap=\"butt\" /><path d=\"M12 35.5h21M13 31.5h19M14 29.5h17M14 16.5h17M11 14h23\" fill=\"none\" stroke=\"#fff\" stroke-width=\"1\" stroke-linejoin=\"miter\" /></g><g id=\"black-king\" class=\"black king\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M22.5 11.63V6\" stroke-linejoin=\"miter\" /><path d=\"M22.5 25s4.5-7.5 3-10.5c0 0-1-2.5-3-2.5s-3 2.5-3 2.5c-1.5 3 3 10.5 3 10.5\" fill=\"#000\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M11.5 37c5.5 3.5 15.5 3.5 21 0v-7s9-4.5 6-10.5c-4-6.5-13.5-3.5-16 4V27v-3.5c-3.5-7.5-13-10.5-16-4-3 6 5 10 5 10V37z\" fill=\"#000\" /><path d=\"M20 8h5\" stroke-linejoin=\"miter\" /><path d=\"M32 29.5s8.5-4 6.03-9.65C34.15 14 25 18 22.5 24.5l.01 2.1-.01-2.1C20 18 9.906 14 6.997 19.85c-2.497 5.65 4.853 9 4.853 9M11.5 30c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0\" stroke=\"#fff\" /></g></defs><rect x=\"7.5\" y=\"7.5\" width=\"375\" height=\"375\" fill=\"none\" stroke=\"#212121\" stroke-width=\"15\" /><g transform=\"translate(20, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M23.328 10.016q-1.742 0-2.414.398-.672.398-.672 1.36 0 .765.5 1.218.508.445 1.375.445 1.196 0 1.914-.843.727-.852.727-2.258v-.32zm2.867-.594v4.992h-1.437v-1.328q-.492.797-1.227 1.18-.734.375-1.797.375-1.343 0-2.14-.75-.79-.758-.79-2.024 0-1.476.985-2.226.992-.75 2.953-.75h2.016V8.75q0-.992-.656-1.531-.649-.547-1.829-.547-.75 0-1.46.18-.711.18-1.368.539V6.062q.79-.304 1.532-.453.742-.156 1.445-.156 1.898 0 2.836.984.937.985.937 2.985z\" /></g><g transform=\"translate(20, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M23.328 10.016q-1.742 0-2.414.398-.672.398-.672 1.36 0 .765.5 1.218.508.445 1.375.445 1.196 0 1.914-.843.727-.852.727-2.258v-.32zm2.867-.594v4.992h-1.437v-1.328q-.492.797-1.227 1.18-.734.375-1.797.375-1.343 0-2.14-.75-.79-.758-.79-2.024 0-1.476.985-2.226.992-.75 2.953-.75h2.016V8.75q0-.992-.656-1.531-.649-.547-1.829-.547-.75 0-1.46.18-.711.18-1.368.539V6.062q.79-.304 1.532-.453.742-.156 1.445-.156 1.898 0 2.836.984.937.985.937 2.985z\" /></g><g transform=\"translate(65, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.922 10.047q0-1.586-.656-2.485-.649-.906-1.79-.906-1.14 0-1.796.906-.649.899-.649 2.485 0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.789-.898.656-.906.656-2.492zm-4.89-3.055q.452-.781 1.14-1.156.695-.383 1.656-.383 1.594 0 2.586 1.266 1 1.265 1 3.328 0 2.062-1 3.328-.992 1.266-2.586 1.266-.96 0-1.656-.375-.688-.383-1.14-1.164v1.312h-1.446V2.258h1.445z\" /></g><g transform=\"translate(65, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.922 10.047q0-1.586-.656-2.485-.649-.906-1.79-.906-1.14 0-1.796.906-.649.899-.649 2.485 0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.789-.898.656-.906.656-2.492zm-4.89-3.055q.452-.781 1.14-1.156.695-.383 1.656-.383 1.594 0 2.586 1.266 1 1.265 1 3.328 0 2.062-1 3.328-.992 1.266-2.586 1.266-.96 0-1.656-.375-.688-.383-1.14-1.164v1.312h-1.446V2.258h1.445z\" /></g><g transform=\"translate(110, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.96 6v1.344q-.608-.336-1.226-.5-.609-.172-1.234-.172-1.398 0-2.172.89-.773.883-.773 2.485 0 1.601.773 2.492.774.883 2.172.883.625 0 1.234-.164.618-.172 1.227-.508v1.328q-.602.281-1.25.422-.64.14-1.367.14-1.977 0-3.14-1.242-1.165-1.242-1.165-3.351 0-2.14 1.172-3.367 1.18-1.227 3.227-1.227.664 0 1.296.14.633.134 1.227.407z\" /></g><g transform=\"translate(110, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.96 6v1.344q-.608-.336-1.226-.5-.609-.172-1.234-.172-1.398 0-2.172.89-.773.883-.773 2.485 0 1.601.773 2.492.774.883 2.172.883.625 0 1.234-.164.618-.172 1.227-.508v1.328q-.602.281-1.25.422-.64.14-1.367.14-1.977 0-3.14-1.242-1.165-1.242-1.165-3.351 0-2.14 1.172-3.367 1.18-1.227 3.227-1.227.664 0 1.296.14.633.134 1.227.407z\" /></g><g transform=\"translate(155, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 6.992V2.258h1.437v12.156h-1.437v-1.312q-.453.78-1.149 1.164-.687.375-1.656.375-1.586 0-2.586-1.266-.992-1.266-.992-3.328 0-2.063.992-3.328 1-1.266 2.586-1.266.969 0 1.656.383.696.375 1.149 1.156zm-4.899 3.055q0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.796-.898.657-.906.657-2.492 0-1.586-.657-2.485-.656-.906-1.796-.906-1.141 0-1.797.906-.649.899-.649 2.485z\" /></g><g transform=\"translate(155, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 6.992V2.258h1.437v12.156h-1.437v-1.312q-.453.78-1.149 1.164-.687.375-1.656.375-1.586 0-2.586-1.266-.992-1.266-.992-3.328 0-2.063.992-3.328 1-1.266 2.586-1.266.969 0 1.656.383.696.375 1.149 1.156zm-4.899 3.055q0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.796-.898.657-.906.657-2.492 0-1.586-.657-2.485-.656-.906-1.796-.906-1.141 0-1.797.906-.649.899-.649 2.485z\" /></g><g transform=\"translate(200, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.555 9.68v.703h-6.61q.094 1.484.89 2.265.806.774 2.235.774.828 0 1.602-.203.781-.203 1.547-.61v1.36q-.774.328-1.586.5-.813.172-1.649.172-2.093 0-3.32-1.22-1.219-1.218-1.219-3.296 0-2.148 1.157-3.406 1.164-1.266 3.132-1.266 1.766 0 2.79 1.14 1.03 1.134 1.03 3.087zm-1.438-.422q-.015-1.18-.664-1.883-.64-.703-1.703-.703-1.203 0-1.93.68-.718.68-.828 1.914z\" /></g><g transform=\"translate(200, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.555 9.68v.703h-6.61q.094 1.484.89 2.265.806.774 2.235.774.828 0 1.602-.203.781-.203 1.547-.61v1.36q-.774.328-1.586.5-.813.172-1.649.172-2.093 0-3.32-1.22-1.219-1.218-1.219-3.296 0-2.148 1.157-3.406 1.164-1.266 3.132-1.266 1.766 0 2.79 1.14 1.03 1.134 1.03 3.087zm-1.438-.422q-.015-1.18-.664-1.883-.64-.703-1.703-.703-1.203 0-1.93.68-.718.68-.828 1.914z\" /></g><g transform=\"translate(245, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.285 2.258v1.195H23.91q-.773 0-1.078.313-.297.312-.297 1.125v.773h2.367v1.117h-2.367v7.633H21.09V6.781h-1.375V5.664h1.375v-.61q0-1.46.68-2.124.68-.672 2.156-.672z\" /></g><g transform=\"translate(245, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.285 2.258v1.195H23.91q-.773 0-1.078.313-.297.312-.297 1.125v.773h2.367v1.117h-2.367v7.633H21.09V6.781h-1.375V5.664h1.375v-.61q0-1.46.68-2.124.68-.672 2.156-.672z\" /></g><g transform=\"translate(290, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 9.937q0-1.562-.649-2.421-.64-.86-1.804-.86-1.157 0-1.805.86-.64.859-.64 2.421 0 1.555.64 2.415.648.859 1.805.859 1.164 0 1.804-.86.649-.859.649-2.414zm1.437 3.391q0 2.234-.992 3.32-.992 1.094-3.04 1.094-.757 0-1.429-.117-.672-.11-1.304-.344v-1.398q.632.344 1.25.508.617.164 1.257.164 1.414 0 2.118-.743.703-.734.703-2.226v-.711q-.446.773-1.141 1.156-.695.383-1.664.383-1.61 0-2.594-1.227-.984-1.226-.984-3.25 0-2.03.984-3.257.985-1.227 2.594-1.227.969 0 1.664.383t1.14 1.156V5.664h1.438z\" /></g><g transform=\"translate(290, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 9.937q0-1.562-.649-2.421-.64-.86-1.804-.86-1.157 0-1.805.86-.64.859-.64 2.421 0 1.555.64 2.415.648.859 1.805.859 1.164 0 1.804-.86.649-.859.649-2.414zm1.437 3.391q0 2.234-.992 3.32-.992 1.094-3.04 1.094-.757 0-1.429-.117-.672-.11-1.304-.344v-1.398q.632.344 1.25.508.617.164 1.257.164 1.414 0 2.118-.743.703-.734.703-2.226v-.711q-.446.773-1.141 1.156-.695.383-1.664.383-1.61 0-2.594-1.227-.984-1.226-.984-3.25 0-2.03.984-3.257.985-1.227 2.594-1.227.969 0 1.664.383t1.14 1.156V5.664h1.438z\" /></g><g transform=\"translate(335, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.164 9.133v5.281h-1.437V9.18q0-1.243-.485-1.86-.484-.617-1.453-.617-1.164 0-1.836.742-.672.742-.672 2.024v4.945h-1.445V2.258h1.445v4.765q.516-.789 1.211-1.18.703-.39 1.617-.39 1.508 0 2.282.938.773.93.773 2.742z\" /></g><g transform=\"translate(335, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.164 9.133v5.281h-1.437V9.18q0-1.243-.485-1.86-.484-.617-1.453-.617-1.164 0-1.836.742-.672.742-.672 2.024v4.945h-1.445V2.258h1.445v4.765q.516-.789 1.211-1.18.703-.39 1.617-.39 1.508 0 2.282.938.773.93.773 2.742z\" /></g><g transform=\"translate(0, 335) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.754 26.996h2.578v-8.898l-2.805.562v-1.437l2.79-.563h1.578v10.336h2.578v1.328h-6.72z\" /></g><g transform=\"translate(375, 335) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.754 26.996h2.578v-8.898l-2.805.562v-1.437l2.79-.563h1.578v10.336h2.578v1.328h-6.72z\" /></g><g transform=\"translate(0, 290) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M8.195 26.996h5.508v1.328H6.297v-1.328q.898-.93 2.445-2.492 1.555-1.57 1.953-2.024.758-.851 1.055-1.437.305-.594.305-1.164 0-.93-.657-1.516-.648-.586-1.695-.586-.742 0-1.57.258-.82.258-1.758.781v-1.593q.953-.383 1.781-.578.828-.196 1.516-.196 1.812 0 2.89.906 1.079.907 1.079 2.422 0 .72-.274 1.368-.265.64-.976 1.515-.196.227-1.243 1.313-1.046 1.078-2.953 3.023z\" /></g><g transform=\"translate(375, 290) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M8.195 26.996h5.508v1.328H6.297v-1.328q.898-.93 2.445-2.492 1.555-1.57 1.953-2.024.758-.851 1.055-1.437.305-.594.305-1.164 0-.93-.657-1.516-.648-.586-1.695-.586-.742 0-1.57.258-.82.258-1.758.781v-1.593q.953-.383 1.781-.578.828-.196 1.516-.196 1.812 0 2.89.906 1.079.907 1.079 2.422 0 .72-.274 1.368-.265.64-.976 1.515-.196.227-1.243 1.313-1.046 1.078-2.953 3.023z\" /></g><g transform=\"translate(0, 245) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.434 22.035q1.132.242 1.765 1.008.64.766.64 1.89 0 1.727-1.187 2.672-1.187.946-3.375.946-.734 0-1.515-.149-.774-.14-1.602-.43V26.45q.656.383 1.438.578.78.196 1.632.196 1.485 0 2.258-.586.782-.586.782-1.703 0-1.032-.727-1.61-.719-.586-2.008-.586h-1.36v-1.297h1.423q1.164 0 1.78-.46.618-.47.618-1.344 0-.899-.64-1.375-.633-.485-1.82-.485-.65 0-1.391.141-.743.14-1.633.437V16.95q.898-.25 1.68-.375.788-.125 1.484-.125 1.797 0 2.844.82 1.046.813 1.046 2.204 0 .968-.554 1.64-.555.664-1.578.922z\" /></g><g transform=\"translate(375, 245) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.434 22.035q1.132.242 1.765 1.008.64.766.64 1.89 0 1.727-1.187 2.672-1.187.946-3.375.946-.734 0-1.515-.149-.774-.14-1.602-.43V26.45q.656.383 1.438.578.78.196 1.632.196 1.485 0 2.258-.586.782-.586.782-1.703 0-1.032-.727-1.61-.719-.586-2.008-.586h-1.36v-1.297h1.423q1.164 0 1.78-.46.618-.47.618-1.344 0-.899-.64-1.375-.633-.485-1.82-.485-.65 0-1.391.141-.743.14-1.633.437V16.95q.898-.25 1.68-.375.788-.125 1.484-.125 1.797 0 2.844.82 1.046.813 1.046 2.204 0 .968-.554 1.64-.555.664-1.578.922z\" /></g><g transform=\"translate(0, 200) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.016 18.035L7.03 24.262h3.985zm-.414-1.375h1.984v7.602h1.664v1.312h-1.664v2.75h-1.57v-2.75H5.75v-1.523z\" /></g><g transform=\"translate(375, 200) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.016 18.035L7.03 24.262h3.985zm-.414-1.375h1.984v7.602h1.664v1.312h-1.664v2.75h-1.57v-2.75H5.75v-1.523z\" /></g><g transform=\"translate(0, 155) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.719 16.66h6.195v1.328h-4.75v2.86q.344-.118.688-.172.343-.063.687-.063 1.953 0 3.094 1.07 1.14 1.07 1.14 2.899 0 1.883-1.171 2.93-1.172 1.039-3.305 1.039-.735 0-1.5-.125-.758-.125-1.57-.375v-1.586q.703.383 1.453.57.75.188 1.586.188 1.351 0 2.14-.711.79-.711.79-1.93 0-1.219-.79-1.93-.789-.71-2.14-.71-.633 0-1.266.14-.625.14-1.281.438z\" /></g><g transform=\"translate(375, 155) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.719 16.66h6.195v1.328h-4.75v2.86q.344-.118.688-.172.343-.063.687-.063 1.953 0 3.094 1.07 1.14 1.07 1.14 2.899 0 1.883-1.171 2.93-1.172 1.039-3.305 1.039-.735 0-1.5-.125-.758-.125-1.57-.375v-1.586q.703.383 1.453.57.75.188 1.586.188 1.351 0 2.14-.711.79-.711.79-1.93 0-1.219-.79-1.93-.789-.71-2.14-.71-.633 0-1.266.14-.625.14-1.281.438z\" /></g><g transform=\"translate(0, 110) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10.137 21.863q-1.063 0-1.688.727-.617.726-.617 1.992 0 1.258.617 1.992.625.727 1.688.727 1.062 0 1.68-.727.624-.734.624-1.992 0-1.266-.625-1.992-.617-.727-1.68-.727zm3.133-4.945v1.437q-.594-.28-1.204-.43-.601-.148-1.195-.148-1.562 0-2.39 1.055-.82 1.055-.938 3.188.46-.68 1.156-1.04.696-.367 1.531-.367 1.758 0 2.774 1.07 1.023 1.063 1.023 2.899 0 1.797-1.062 2.883-1.063 1.086-2.828 1.086-2.024 0-3.094-1.547-1.07-1.555-1.07-4.5 0-2.766 1.312-4.406 1.313-1.649 3.524-1.649.593 0 1.195.117.61.118 1.266.352z\" /></g><g transform=\"translate(375, 110) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10.137 21.863q-1.063 0-1.688.727-.617.726-.617 1.992 0 1.258.617 1.992.625.727 1.688.727 1.062 0 1.68-.727.624-.734.624-1.992 0-1.266-.625-1.992-.617-.727-1.68-.727zm3.133-4.945v1.437q-.594-.28-1.204-.43-.601-.148-1.195-.148-1.562 0-2.39 1.055-.82 1.055-.938 3.188.46-.68 1.156-1.04.696-.367 1.531-.367 1.758 0 2.774 1.07 1.023 1.063 1.023 2.899 0 1.797-1.062 2.883-1.063 1.086-2.828 1.086-2.024 0-3.094-1.547-1.07-1.555-1.07-4.5 0-2.766 1.312-4.406 1.313-1.649 3.524-1.649.593 0 1.195.117.61.118 1.266.352z\" /></g><g transform=\"translate(0, 65) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.25 16.66h7.5v.672L9.516 28.324H7.867l3.985-10.336H6.25z\" /></g><g transform=\"translate(375, 65) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.25 16.66h7.5v.672L9.516 28.324H7.867l3.985-10.336H6.25z\" /></g><g transform=\"translate(0, 20) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10 22.785q-1.125 0-1.773.602-.641.601-.641 1.656t.64 1.656q.649.602 1.774.602t1.773-.602q.649-.61.649-1.656 0-1.055-.649-1.656-.64-.602-1.773-.602zm-1.578-.672q-1.016-.25-1.586-.945-.563-.695-.563-1.695 0-1.399.993-2.211 1-.813 2.734-.813 1.742 0 2.734.813.993.812.993 2.21 0 1-.57 1.696-.563.695-1.571.945 1.14.266 1.773 1.04.641.773.641 1.89 0 1.695-1.04 2.602-1.03.906-2.96.906t-2.969-.906Q6 26.738 6 25.043q0-1.117.64-1.89.641-.774 1.782-1.04zm-.578-2.492q0 .906.562 1.414.57.508 1.594.508 1.016 0 1.586-.508.578-.508.578-1.414 0-.906-.578-1.414-.57-.508-1.586-.508-1.023 0-1.594.508-.562.508-.562 1.414z\" /></g><g transform=\"translate(375, 20) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10 22.785q-1.125 0-1.773.602-.641.601-.641 1.656t.64 1.656q.649.602 1.774.602t1.773-.602q.649-.61.649-1.656 0-1.055-.649-1.656-.64-.602-1.773-.602zm-1.578-.672q-1.016-.25-1.586-.945-.563-.695-.563-1.695 0-1.399.993-2.211 1-.813 2.734-.813 1.742 0 2.734.813.993.812.993 2.21 0 1-.57 1.696-.563.695-1.571.945 1.14.266 1.773 1.04.641.773.641 1.89 0 1.695-1.04 2.602-1.03.906-2.96.906t-2.969-.906Q6 26.738 6 25.043q0-1.117.64-1.89.641-.774 1.782-1.04zm-.578-2.492q0 .906.562 1.414.57.508 1.594.508 1.016 0 1.586-.508.578-.508.578-1.414 0-.906-.578-1.414-.57-.508-1.586-.508-1.023 0-1.594.508-.562.508-.562 1.414z\" /></g><rect x=\"15\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark a1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"330\" width=\"45\" height=\"45\" class=\"square light b1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark c1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"330\" width=\"45\" height=\"45\" class=\"square light d1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark e1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"330\" width=\"45\" height=\"45\" class=\"square light f1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark g1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"330\" width=\"45\" height=\"45\" class=\"square light h1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"285\" width=\"45\" height=\"45\" class=\"square light a2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark b2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"285\" width=\"45\" height=\"45\" class=\"square light c2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark d2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"285\" width=\"45\" height=\"45\" class=\"square light e2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark f2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"285\" width=\"45\" height=\"45\" class=\"square light g2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark h2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"15\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark a3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"240\" width=\"45\" height=\"45\" class=\"square light b3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark c3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"240\" width=\"45\" height=\"45\" class=\"square light d3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark e3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"240\" width=\"45\" height=\"45\" class=\"square light f3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark g3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"240\" width=\"45\" height=\"45\" class=\"square light h3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"195\" width=\"45\" height=\"45\" class=\"square light a4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark b4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"195\" width=\"45\" height=\"45\" class=\"square light c4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark d4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"195\" width=\"45\" height=\"45\" class=\"square light e4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark f4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"195\" width=\"45\" height=\"45\" class=\"square light g4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark h4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"15\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark a5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"150\" width=\"45\" height=\"45\" class=\"square light b5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark c5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"150\" width=\"45\" height=\"45\" class=\"square light d5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark e5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"150\" width=\"45\" height=\"45\" class=\"square light f5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark g5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"150\" width=\"45\" height=\"45\" class=\"square light h5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"105\" width=\"45\" height=\"45\" class=\"square light a6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark b6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"105\" width=\"45\" height=\"45\" class=\"square light c6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark d6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"105\" width=\"45\" height=\"45\" class=\"square light e6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark f6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"105\" width=\"45\" height=\"45\" class=\"square light g6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark h6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"15\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark a7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"60\" width=\"45\" height=\"45\" class=\"square light b7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark c7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"60\" width=\"45\" height=\"45\" class=\"square light d7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark e7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"60\" width=\"45\" height=\"45\" class=\"square light f7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark g7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"60\" width=\"45\" height=\"45\" class=\"square light h7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"15\" width=\"45\" height=\"45\" class=\"square light a8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark b8\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"15\" width=\"45\" height=\"45\" class=\"square light c8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark d8\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"15\" width=\"45\" height=\"45\" class=\"square light e8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark f8\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"15\" width=\"45\" height=\"45\" class=\"square light g8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark h8\" stroke=\"none\" fill=\"#d18b47\" /><use href=\"#white-king\" xlink:href=\"#white-king\" transform=\"translate(285, 330)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(60, 285)\" /><use href=\"#black-rook\" xlink:href=\"#black-rook\" transform=\"translate(195, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(15, 240)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(285, 240)\" /><use href=\"#white-queen\" xlink:href=\"#white-queen\" transform=\"translate(105, 150)\" /><use href=\"#black-knight\" xlink:href=\"#black-knight\" transform=\"translate(240, 105)\" /><use href=\"#black-rook\" xlink:href=\"#black-rook\" transform=\"translate(150, 60)\" /><use href=\"#black-king\" xlink:href=\"#black-king\" transform=\"translate(285, 15)\" /></svg>"
      ],
      "text/plain": [
       "Board('6k1/3r4/5n2/2Q5/8/P5P1/1P2r3/6K1 w - - 9 56')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "b = chess.Board(start_fens[ind_test[567]])\n",
    "display(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a1715fbe-27aa-43f7-8417-62953309bbc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[start] fork [end]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['[start]', 'fork', '[end]']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(themes[ind_test[567]])\n",
    "translate(moves_san_test[567], seq_len_dec, model_loaded, vectorizer_enc_loaded, vectorizer_dec_loaded)\n",
    "#translate('Bxf7 Kxf7 Ne6 dxe6 Qxd8 Nc6 Qd2', seq_len_dec, model_loaded, vectorizer_enc_loaded, vectorizer_dec_loaded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d01029-648f-4ee1-9cd0-135eff8545ec",
   "metadata": {},
   "source": [
    "Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183e5f03-bf1c-4fd7-afdc-3af3c4bfe828",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = []\n",
    "recall = []\n",
    "f1 = []\n",
    "for i in range(len(ind_test)):\n",
    "    pred = translate(moves_san_test[i], seq_len_dec, model_loaded, vectorizer_enc_loaded, vectorizer_dec_loaded)[1:-1]\n",
    "    true = themes[ind_test[i]].split(' ')[1:-1]\n",
    "    tp = len(set(pred).intersection(true))\n",
    "    precision.append(tp/len(pred))\n",
    "    recall.append(tp/len(true))\n",
    "    f1.append(2*tp/(len(pred) + len(true)))\n",
    "print('Precision =', sum(precision)*100/len(precision), '%')\n",
    "print('Recall =', sum(recall)*100/len(recall), '%')\n",
    "print('F1 Score =', sum(f1)*100/len(f1), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a290bc44-3f48-4a60-9954-36eb0f663a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notes for improvement!!\n",
    "# include move numbers along with the moves\n",
    "# Take only fen as input; allow stockfish to generate the rest of the moves.\n",
    "# Add more tags, consider all possible variations after a move using stockfish, take union of explanation of all variations to understand \n",
    "# the move in question"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
